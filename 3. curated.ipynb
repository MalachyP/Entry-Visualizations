{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATIVE_IN = \"2. raw\"\n",
    "RELATIVE_OUT = \"3. curated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(952, 31)\n"
     ]
    }
   ],
   "source": [
    "offers_raw = pd.read_csv(f\"{RELATIVE_IN}/offers.csv\", index_col=0)\n",
    "print(offers_raw.shape)\n",
    "#print(offers_raw.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offer uni\n",
       "The University of Melbourne                        163\n",
       "Deakin University                                  104\n",
       "Griffith University                                 84\n",
       "The University of Western Australia                 61\n",
       "The University of Notre Dame Sydney                 54\n",
       "The University of Notre Dame Fremantle              51\n",
       "Australian National University                      32\n",
       "The University of Queensland (CQ-WB RMP)            30\n",
       "The University of Queensland                        29\n",
       "The University of Wollongong                        27\n",
       "Macquarie University                                27\n",
       "The University of Queensland (Greater Brisbane)     14\n",
       "The University of Queensland (DD MP)                12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_raw[\"offer uni\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "UQ_NAME = \"The University of Queensland\"\n",
    "RMP_ENDINGS = [\"(DD MP)\", \"(CQ-WB RMP)\"]\n",
    "METRO_ENDING = \"(Greater Brisbane)\"\n",
    "\n",
    "# fixing the queensland column\n",
    "offers = offers_raw.copy()\n",
    "\n",
    "# get the RMP types\n",
    "offers.loc[offers[\"uq type\"] == \"RMP\", \"offer uni\"] = UQ_NAME + \" (RMP)\"\n",
    "\n",
    "# change the MD and WB to correct types\n",
    "offers.loc[offers[\"offer uni\"].isin([f\"{UQ_NAME} {x}\" for x in RMP_ENDINGS ]), \"offer uni\"] = UQ_NAME + \" (RMP)\"\n",
    "offers.loc[offers[\"interview uni\"].isin([f\"{UQ_NAME} {x}\" for x in RMP_ENDINGS ]), \"interview uni\"] = UQ_NAME + \" (RMP)\"\n",
    "\n",
    "# change greater brisbance\n",
    "metro_mask_offer = (offers[\"offer uni\"] == UQ_NAME) | (offers[\"offer uni\"] == f\"{UQ_NAME} {METRO_ENDING}\")\n",
    "metro_mask_interview = (offers[\"interview uni\"] == UQ_NAME) | (offers[\"interview uni\"] == f\"{UQ_NAME} {METRO_ENDING}\")\n",
    "offers.loc[metro_mask_offer, \"offer uni\"] = f\"{UQ_NAME} (Metro)\"\n",
    "offers.loc[metro_mask_interview, \"interview uni\"] = f\"{UQ_NAME} (Metro)\"\n",
    "\n",
    "# dropping the type\n",
    "offers.drop(columns=\"uq type\", inplace=True)\n",
    "\n",
    "# fixing the interview column\n",
    "offers.loc[(offers[\"year\"] == 2023) & (offers[\"interview uni\"].isna()), \"interviewed?\"] = \"Yes\"\n",
    "offers.loc[(offers[\"year\"] == 2023) & (offers[\"interview uni\"].notna() & (offers[\"offer uni\"].notna())), \"interviewed?\"] = \"No\"\n",
    "\n",
    "# make the notes lowe case\n",
    "offers.loc[:, \"notes\"] = offers[\"notes\"].str.lower()\n",
    "\n",
    "# drop un necessary columns\n",
    "offers.drop(columns=[\"status\", \"timestamp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offer uni\n",
       "The University of Melbourne               163\n",
       "Deakin University                         104\n",
       "Griffith University                        84\n",
       "The University of Queensland (RMP)         61\n",
       "The University of Western Australia        61\n",
       "The University of Notre Dame Sydney        54\n",
       "The University of Notre Dame Fremantle     51\n",
       "Australian National University             32\n",
       "The University of Wollongong               27\n",
       "Macquarie University                       27\n",
       "The University of Queensland (Metro)       24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers[\"offer uni\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the marker type column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 28)\n",
      "(264, 28)\n",
      "(264, 28)\n",
      "(0, 28)\n"
     ]
    }
   ],
   "source": [
    "print(offers[(offers[\"offer uni place type\"].isna()) & (offers[\"offer uni\"].isna())].shape)  # offer uni and offer uni type notna\n",
    "print(offers[(offers[\"offer uni\"].isna())].shape)                                            # offer uni notna\n",
    "print(offers[(offers[\"offer uni place type\"].isna())].shape)                                 # offer uni type notna\n",
    "\n",
    "print(offers[(offers[\"offer uni\"].isna()) & (offers[\"places selected\"].isna())].shape)       # offer uni na with places selected also na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "places selected\n",
       "CSP, BMP          327\n",
       "CSP, BMP, FFP     119\n",
       "All                94\n",
       "CSP & BMP Only     88\n",
       "CSP                47\n",
       "CSP Only           29\n",
       "FFP                 5\n",
       "BMP                 5\n",
       "CSP, FFP            5\n",
       "BMP, FFP            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers[\"places selected\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "places selected\n",
       "[CSP, BMP]         415\n",
       "[CSP, BMP, FFP]    213\n",
       "[CSP]               76\n",
       "[FFP]                5\n",
       "[BMP]                5\n",
       "[CSP, FFP]           5\n",
       "[BMP, FFP]           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixing the places selected column with dictionary\n",
    "CSP = \"CSP\"\n",
    "BMP = \"BMP\"\n",
    "FFP = \"FFP\"\n",
    "\n",
    "rename_places_selected = {\n",
    "    \"CSP, BMP\": [CSP, BMP],\n",
    "    \"CSP & BMP Only\": [CSP, BMP],\n",
    "\n",
    "    \"CSP, BMP, FFP\": [CSP, BMP, FFP],\n",
    "    \"All\": [CSP, BMP, FFP],\n",
    "\n",
    "    \"CSP\": [CSP],\n",
    "    \"CSP Only\": [CSP],\n",
    "    \"CSP, FFP\": [CSP, FFP],\n",
    "    \n",
    "    \"BMP\": [BMP],\n",
    "    \"BMP, FFP\": [BMP, FFP],\n",
    "\n",
    "    \"FFP\": [FFP],\n",
    "}\n",
    "\n",
    "offers[\"places selected\"] = offers[\"places selected\"].apply(lambda x: rename_places_selected[x] \n",
    "                                                            if (not pd.isna(x)) and (rename_places_selected.get(x)) else x)\n",
    "\n",
    "offers[\"places selected\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offer uni place type\n",
       "CSP    491\n",
       "BMP    131\n",
       "FFP     66\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers['offer uni place type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks how many times someone gets rejected and the places they selected aren't recorded\n",
    "offers[offers[\"places selected\"].isna()][\"interview uni\"].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers[\"marker\"] = offers[\"offer uni place type\"]\n",
    "offers.loc[offers[\"marker\"].isna(), \"marker\"] = offers[\"places selected\"]\n",
    "#offers.loc[offers[\"marker\"].isna(), \"marker\"] = \"Unknown\"\n",
    "offers[\"marker\"].isna().sum()\n",
    "\n",
    "#offers[\"marker\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_8080\\1972849651.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' 'nan'\n",
      " '1.0' '1.0' '3.0' '1.0' 'nan' '4.0' '3.0' '1.0' '1.0' '5.0' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' '5.0' '2.0' 'nan' '1.0'\n",
      " '1.0' '1.0' 'nan' 'nan' '1.0' '1.0' 'nan' '1.0' '4.0' 'nan' 'nan' 'nan'\n",
      " 'nan' '1.0' 'nan' 'nan' 'nan' '1.0' '1.0' 'nan' '1.0' '4.0' '1.0' '1.0'\n",
      " 'nan' '1.0' '1.0' '2.0' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' '2.0' '1.0'\n",
      " 'nan' '1.0' 'nan' '2.0' 'nan' 'nan' '2.0' '2.0' '1.0' 'nan' '1.0' '1.0'\n",
      " '2.0' 'nan' 'nan' 'nan' '1.0' '2.0' 'nan' '1.0' 'nan' 'nan' '1.0' '1.0'\n",
      " '1.0' 'nan' '1.0' '1.0' 'nan' '1.0' '1.0' '1.0' 'nan' '1.0' '1.0' 'nan'\n",
      " '1.0' '2.0' '2.0' '2.0' 'nan' '1.0' '1.0' '1.0' '1.0' '2.0' '1.0' '3.0'\n",
      " '1.0' '2.0' 'nan' '1.0' '1.0' '1.0' 'nan' '1.0' 'nan' '1.0' 'nan' 'nan'\n",
      " 'nan' '2.0' '6.0' '2.0' '1.0' 'nan' 'nan' 'nan' '1.0' '1.0' '2.0' '2.0'\n",
      " '1.0' '2.0' '1.0' '1.0' '3.0' '1.0' '1.0' '1.0' 'nan' '2.0' '2.0' '1.0'\n",
      " 'nan' '1.0' 'nan' '1.0' '1.0' '1.0' '2.0' '1.0' '2.0' '1.0' 'nan' '1.0'\n",
      " '3.0' 'nan' '1.0' '1.0' '2.0' '2.0' '3.0' '1.0' '1.0' '1.0' '1.0' '2.0'\n",
      " '2.0' '1.0' '1.0' 'nan' '2.0' 'nan' '1.0' '1.0' '1.0' '2.0' '1.0' 'nan'\n",
      " '5.0' '1.0' '1.0' '4.0' '1.0' 'nan' '1.0' 'nan' '1.0' '1.0' '1.0' '6.0'\n",
      " '2.0' 'nan' 'nan' '1.0' '2.0' '1.0' 'nan' '1.0' 'nan' '1.0' '1.0' '2.0'\n",
      " '3.0' '1.0' '1.0' '3.0' 'nan' '1.0' '1.0' '2.0' '2.0' 'nan' '1.0' 'nan'\n",
      " '1.0' 'nan' '1.0' '3.0' '1.0' '1.0' 'nan' '2.0' '1.0' 'nan' '4.0' '1.0'\n",
      " 'nan' 'nan' 'nan' '1.0' '1.0' '1.0' '1.0' '1.0' '5.0' 'nan' 'nan' '3.0'\n",
      " '2.0' '2.0' 'nan' '2.0' '1.0' '1.0' '1.0' 'nan' '1.0' '1.0' 'nan' '2.0'\n",
      " '1.0' 'nan' '2.0' '1.0' '4.0' '1.0' '1.0' '1.0' '1.0' '1.0' '1.0' '2.0'\n",
      " 'nan' '1.0' '1.0' '1.0' '1.0' '3.0' 'nan' '1.0' '6.0' '1.0' '1.0' '1.0'\n",
      " '1.0' 'nan' 'nan' '2.0' '1.0' '1.0' '1.0' '1.0' 'nan' '1.0' '2.0' '3.0'\n",
      " '2.0' '4.0' '2.0' 'nan' '1.0' '1.0' '1.0' '6.0' '2.0' 'nan' '1.0' '1.0'\n",
      " 'nan' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan' '1.0' 'nan' '1.0' 'nan' '1.0'\n",
      " 'nan' '1.0' '1.0' 'nan' '1.0' '4.0' '1.0' '5.0' 'nan' '1.0' '1.0' 'nan'\n",
      " '1.0' '2.0' 'nan' 'nan' '4.0' 'nan' '3.0' 'nan' '1.0' '5.0' 'nan' '3.0'\n",
      " '1.0' '3.0' '1.0' 'nan' 'nan' '1.0' '4.0' 'nan' '6.0' '4.0' '1.0' '1.0'\n",
      " '1.0' '3.0' '3.0' '5.0' '1.0' '4.0' '1.0' '1.0' '3.0' '2.0' '1.0' '2.0'\n",
      " '1.0' '1.0' '1.0' 'nan' '1.0' '1.0' '3.0' '3.0' '1.0' '4.0' 'nan' 'nan'\n",
      " '3.0' '1.0' '1.0' 'nan' 'nan' 'nan' '1.0' '3.0' 'nan' 'nan' '1.0' '1.0'\n",
      " '2.0' 'nan' '1.0' 'nan' 'nan' '1.0' '1.0' '2.0' '1.0' '1.0' '2.0' '1.0'\n",
      " '1.0' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' '2.0' 'nan'\n",
      " '4.0' 'nan' 'nan' '3.0' 'nan' 'nan' 'nan' '3.0' '1.0' '1.0' 'nan' 'nan'\n",
      " '1.0' 'nan' 'nan' 'nan' '6.0' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan'\n",
      " 'nan' '3.0' '2.0' 'nan' 'nan' 'nan' '4.0' 'nan' 'nan' '1.0' '1.0' 'nan'\n",
      " '1.0' '6.0' '1.0' 'nan' '2.0' 'nan' '1.0' '1.0' 'nan' '1.0' '1.0' '2.0'\n",
      " '1.0' 'nan' 'nan' 'nan' '1.0' '1.0' '1.0' 'nan' 'nan' 'nan' '1.0' '1.0'\n",
      " '3.0' 'nan' '1.0' '5.0' 'nan' '1.0' '5.0' 'nan' '1.0' '2.0' 'nan' 'nan'\n",
      " '1.0' '3.0' '1.0' '1.0' '3.0' '3.0' '1.0' '3.0' 'nan' 'nan' 'nan' 'nan'\n",
      " '2.0' 'nan' '1.0' '1.0' '1.0' 'nan' '1.0' 'nan' '1.0' '5.0' '1.0' '3.0'\n",
      " '4.0' 'nan' '1.0' '1.0' '1.0' 'nan' '1.0' 'nan' '3.0' '1.0' '3.0' '1.0'\n",
      " '1.0' '1.0' '1.0' 'nan' '1.0' '1.0' '1.0' '1.0' '1.0' '1.0' '3.0' '2.0'\n",
      " '3.0' '1.0' '1.0' '1.0' 'nan' '3.0' 'nan' '1.0' '1.0' 'nan' '1.0' 'nan'\n",
      " '1.0' '1.0' '1.0' '1.0' '1.0' '6.0' '4.0' '1.0' 'nan' '1.0' '1.0' '1.0'\n",
      " '1.0' '2.0' '3.0' 'nan' '2.0' '1.0' '1.0' '1.0' '1.0' '1.0' '2.0' '1.0'\n",
      " '1.0' '1.0' '3.0' 'nan' 'nan' '2.0' '1.0' '1.0' '1.0' '1.0' 'nan' 'nan'\n",
      " 'nan' '1.0' '1.0' 'nan' '1.0' '5.0' 'nan' '1.0' '1.0' '2.0' '4.0' '1.0'\n",
      " 'nan' 'nan' '1.0' '1.0' '1.0' '2.0' 'nan' '1.0' 'nan' '1.0' '2.0' 'nan'\n",
      " '1.0' '1.0' '2.0' '1.0' '2.0' 'nan' '1.0' 'nan' '4.0' '1.0' '1.0' '1.0'\n",
      " '1.0' '4.0' '1.0' 'nan' '1.0' '1.0' '1.0' '1.0' '4.0' '1.0' 'nan' '1.0'\n",
      " '1.0' '2.0' 'nan' '1.0' '1.0' '2.0' '1.0' '1.0' '1.0' '3.0' '1.0' '1.0'\n",
      " '1.0' '1.0' 'nan' '3.0' '1.0' '1.0' 'nan' '5.0' '1.0' '1.0' '1.0' '1.0'\n",
      " '1.0' '2.0' '1.0' '1.0' '1.0' '1.0' '1.0' '3.0' '1.0' '3.0' '1.0' '1.0'\n",
      " '1.0' '1.0' '1.0' '1.0' '1.0' '1.0' '1.0' '2.0' '3.0' '1.0' '1.0' '1.0'\n",
      " '3.0' '1.0' '1.0' '1.0' '1.0' 'nan' 'nan' '2.0' '1.0' '5.0' '1.0' '2.0'\n",
      " '4.0' '3.0' 'nan' 'nan' '4.0' '1.0' '1.0' '1.0' '1.0' 'nan' '1.0' '1.0'\n",
      " '3.0' 'nan' '4.0' 'nan' '4.0' '1.0' '6.0' '1.0' '1.0' '1.0' '3.0' '6.0'\n",
      " '1.0' '1.0' 'nan' '1.0' '1.0' '1.0' '3.0' 'nan' '1.0' '1.0' '1.0' 'nan'\n",
      " '3.0' 'nan' 'nan' '2.0' 'nan' '2.0' 'nan' '1.0' '1.0' '4.0' '1.0' 'nan'\n",
      " '2.0' '1.0' 'nan' '5.0' '1.0' '5.0' '1.0' '2.0' 'nan' '1.0' '2.0' '2.0'\n",
      " 'nan' '1.0' '2.0' '4.0' '3.0' '1.0' '3.0' '1.0' '3.0' '1.0' 'nan' '2.0'\n",
      " '1.0' '1.0' '3.0' '1.0' 'nan' '2.0' '2.0' '1.0' '1.0' '1.0' '1.0' '4.0'\n",
      " '1.0' 'nan' '1.0' 'nan' '1.0' '1.0' 'nan' '1.0' '1.0' '1.0' '5.0' '4.0'\n",
      " '2.0' '1.0' '1.0' '1.0' '1.0' '1.0' '5.0' 'nan' 'nan' 'nan' '1.0' 'nan'\n",
      " '4.0' '1.0' '5.0' '1.0' 'nan' '1.0' '2.0' '1.0' '1.0' '1.0' '1.0' '2.0'\n",
      " '1.0' '3.0' '1.0' '2.0' 'nan' '2.0' '4.0' '2.0' 'nan' '1.0' '2.0' '1.0'\n",
      " '3.0' '6.0' '1.0' '1.0' '1.0' '4.0' '6.0' 'nan' '3.0' '1.0' '1.0' '1.0'\n",
      " '1.0' '1.0' '4.0' 'nan' '1.0' '3.0' '1.0' '1.0' 'nan' '1.0' '3.0' '1.0'\n",
      " '2.0' '1.0' '2.0' '3.0' '2.0' '4.0' 'nan' '3.0' '2.0' 'nan' '1.0' '1.0'\n",
      " '1.0' '3.0' '1.0' '1.0' '1.0' 'nan' '1.0' '1.0' 'nan' '1.0' '1.0' '2.0'\n",
      " '2.0' '1.0' 'nan' 'nan' '6.0' '1.0' '4.0' '4.0' '1.0' 'nan' '1.0' '1.0'\n",
      " '1.0' 'nan' '1.0' 'nan' '1.0' 'nan' '1.0' '1.0' 'nan' '2.0' '1.0' '1.0'\n",
      " '1.0' '1.0' '1.0' '3.0' '2.0' '1.0' '1.0' '5.0' '1.0' '1.0' 'nan' '1.0'\n",
      " '1.0' 'nan' 'nan' '6.0' '5.0' 'nan' '4.0' '1.0' '1.0' '1.0' '1.0' '3.0'\n",
      " '4.0' 'nan' 'nan' 'nan' '1.0' '1.0' '3.0' '2.0' '2.0' '1.0' '6.0' '1.0'\n",
      " '1.0' '1.0' '5.0' 'nan' '2.0' '1.0' '6.0' '1.0' '4.0' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' '1.0' '1.0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  offers.loc[:, string_col] = offers[string_col].astype(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_8080\\1972849651.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['1.0' 'nan' '5.0' '1.0' '5.0' '1.0' '2.0' 'nan' '1.0' '1.0' '1.0' '4.0'\n",
      " 'nan' 'nan' '1.0' 'nan' '4.0' 'nan' '2.0' 'nan' 'nan' 'nan' '1.0' '1.0'\n",
      " '2.0' '1.0' '1.0' '1.0' 'nan' '1.0' '4.0' '1.0' '4.0' '1.0' '1.0' 'nan'\n",
      " 'nan' 'nan' '2.0' '1.0' 'nan' 'nan' '1.0' 'nan' '3.0' '5.0' '5.0' '1.0'\n",
      " '2.0' 'nan' '2.0' '1.0' '1.0' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan'\n",
      " '1.0' 'nan' 'nan' '1.0' 'nan' 'nan' '3.0' '1.0' '1.0' '1.0' '1.0' 'nan'\n",
      " '6.0' 'nan' '1.0' '1.0' '1.0' '5.0' '1.0' '1.0' 'nan' '1.0' 'nan' 'nan'\n",
      " '1.0' '1.0' '1.0' '1.0' 'nan' 'nan' '1.0' 'nan' '1.0' '1.0' 'nan' 'nan'\n",
      " 'nan' '1.0' 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' '2.0'\n",
      " 'nan' '1.0' '1.0' '1.0' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' '3.0' 'nan' 'nan' 'nan' '1.0' 'nan' '2.0' 'nan' '1.0' '1.0'\n",
      " '1.0' '1.0' '2.0' '1.0' 'nan' '1.0' '1.0' '1.0' 'nan' 'nan' '1.0' 'nan'\n",
      " 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan'\n",
      " '6.0' 'nan' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan'\n",
      " '2.0' '2.0' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' 'nan' '5.0' 'nan' '1.0' 'nan' 'nan' 'nan' '1.0' 'nan' '3.0'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan' 'nan' 'nan' '6.0'\n",
      " '1.0' '2.0' '1.0' 'nan' '1.0' 'nan' '1.0' 'nan' '1.0' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' '1.0' '3.0' 'nan' '1.0'\n",
      " 'nan' '5.0' 'nan' '2.0' 'nan' 'nan' '1.0' 'nan' 'nan' '2.0' '3.0' 'nan'\n",
      " '1.0' '1.0' '3.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' '6.0' '3.0' 'nan'\n",
      " 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' '2.0' 'nan' 'nan' '1.0' 'nan'\n",
      " 'nan' '3.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '4.0' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' '1.0' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' '3.0' 'nan' 'nan' '2.0'\n",
      " '1.0' '3.0' 'nan' '3.0' 'nan' 'nan' 'nan' '1.0' '1.0' '6.0' 'nan' 'nan'\n",
      " '1.0' '1.0' '1.0' 'nan' '1.0' 'nan' '5.0' 'nan' '1.0' 'nan' '1.0' 'nan'\n",
      " '2.0' 'nan' 'nan' '3.0' 'nan' '1.0' 'nan' '1.0' '6.0' 'nan' 'nan' '2.0'\n",
      " 'nan' '1.0' '2.0' '1.0' 'nan' '1.0' '2.0' '1.0' 'nan' '2.0' '1.0' 'nan'\n",
      " 'nan' '2.0' 'nan' '2.0' '2.0' 'nan' '3.0' '2.0' '2.0' 'nan' 'nan' 'nan'\n",
      " 'nan' '1.0' '1.0' 'nan' 'nan' '1.0' 'nan' 'nan' '2.0' '1.0' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' '1.0' 'nan' '3.0' '1.0' '1.0'\n",
      " '1.0' 'nan' 'nan' '1.0' '1.0' '4.0' 'nan' 'nan' '1.0' '1.0' 'nan' 'nan'\n",
      " 'nan' '2.0' 'nan' '1.0' '1.0' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' '1.0' 'nan' 'nan' '1.0' '5.0' '2.0' '2.0' '1.0' 'nan' '1.0' '1.0'\n",
      " '3.0' '2.0' '3.0' '1.0' '6.0' '3.0' '1.0' '2.0' 'nan' 'nan' '4.0' '1.0'\n",
      " 'nan' '1.0' '2.0' '4.0' 'nan' '3.0' '1.0' '1.0' '1.0' 'nan' '2.0' '1.0'\n",
      " '3.0' 'nan' '1.0' '1.0' '1.0' '1.0' '2.0' '1.0' '1.0' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' 'nan' '1.0' 'nan' '2.0' 'nan' 'nan' '1.0' 'nan' 'nan' '1.0'\n",
      " 'nan' '5.0' '1.0' '1.0' 'nan' 'nan' 'nan' '1.0' '1.0' '1.0' 'nan' 'nan'\n",
      " 'nan' '3.0' 'nan' '1.0' '2.0' 'nan' '2.0' '1.0' 'nan' 'nan' '1.0' '1.0'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' '1.0' '1.0' '5.0'\n",
      " 'nan' '1.0' 'nan' 'nan' 'nan' '6.0' 'nan' '2.0' 'nan' 'nan' 'nan' '1.0'\n",
      " '3.0' '2.0' 'nan' 'nan' 'nan' '2.0' 'nan' '1.0' '2.0' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan' 'nan' '1.0' 'nan' '1.0'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' '2.0' '2.0' 'nan' '3.0' 'nan' 'nan' 'nan'\n",
      " 'nan' '1.0' '1.0' '3.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' '1.0'\n",
      " '1.0' 'nan' 'nan' '6.0' 'nan' '4.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " '2.0' '1.0' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' '1.0' 'nan' '1.0' '1.0' 'nan' '1.0' '3.0' 'nan' 'nan' 'nan'\n",
      " 'nan' '1.0' 'nan' '3.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '3.0' 'nan'\n",
      " 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '2.0' 'nan' 'nan'\n",
      " 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " '2.0' 'nan' 'nan' 'nan' 'nan' '1.0' '3.0' 'nan' 'nan' '1.0' 'nan' 'nan'\n",
      " '3.0' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan'\n",
      " '1.0' '3.0' 'nan' '2.0' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' '5.0'\n",
      " 'nan' '1.0' '6.0' 'nan' '1.0' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' '1.0'\n",
      " '1.0' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0'\n",
      " 'nan' '1.0' 'nan' '1.0' 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '2.0' '1.0' '2.0' 'nan' '1.0'\n",
      " 'nan' 'nan' '4.0' 'nan' '3.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' '2.0' '2.0' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' '3.0' '1.0' 'nan' 'nan' 'nan' 'nan' '4.0' 'nan' '1.0' 'nan'\n",
      " '1.0' 'nan' '1.0' '1.0' '1.0' '1.0' '1.0' '1.0' 'nan' '1.0' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan'\n",
      " '1.0' 'nan' '1.0' '1.0' '1.0' 'nan' '1.0' 'nan' 'nan' '1.0' 'nan' 'nan'\n",
      " 'nan' '1.0' 'nan' '3.0' 'nan' '1.0' 'nan' 'nan' '1.0' '1.0' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' '4.0' 'nan' 'nan' '1.0' 'nan'\n",
      " 'nan' '4.0' '2.0' '2.0' '3.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " '2.0' '1.0' '4.0' '1.0' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan' '4.0' 'nan'\n",
      " 'nan' 'nan' '2.0' '1.0' '1.0' 'nan' 'nan' 'nan' '1.0' '2.0' '1.0' '3.0'\n",
      " '2.0' '1.0' 'nan' '5.0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  offers.loc[:, string_col] = offers[string_col].astype(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_8080\\1972849651.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['2' '0' '2' '2' '0' '0' '0' '6' '2' '0' '0' '0' '8' '6' '0' '0' '0' '2'\n",
      " '4' '2' '10' '0' '0' '0' '2' '0' '2' '0' '4' '2' '2' '0' '2' '0' '0' '0'\n",
      " '6' '10' '0' '0' '0' '8' '0' '0' '0' '0' '0' '0' '0' '0' '4' '0' '0' '0'\n",
      " '10' '0' '0' '0' '10' '14' '0' '8' '0' '0' '2' '0' '0' '0' '0' '0' '0'\n",
      " '0' '2' '8' '0' '2' '6' '0' '0' '4' '12' '2' '8' '2' '0' '2' '0' '2' '0'\n",
      " '0' '0' '0' '0' '0' '4' '0' '0' '0' '0' '0' '6' '4' '0' '0' '0' '0' '0'\n",
      " '0' '4' '0' '0' '0' '0' '10' '8' '0' '6' '2' '2' '0' '2' '0' '0' '0' '0'\n",
      " '12' '2' '0' '2' '10' '6' '10' '0' '0' '0' '0' '6' '0' '2' '8' '0' '8'\n",
      " '8' '0' '0' '0' '0' '2' '0' '8' '2' '6' '0' '0' '0' '14' '0' '4' '12' '0'\n",
      " '4' '2' '8' '0' '0' '0' '0' '14' '0' '0' '0' '0' '0' '0' '0' '0' '0' '4'\n",
      " '0' '6' '0' '2' '2' '0' '2' '2' '0' '12' '8' '2' '8' '0' '2' '8' '0' '0'\n",
      " '0' '0' '0' '0' '0' '12' '0' '0' '4' '0' '0' '2' '0' '0' '0' '0' '2' '0'\n",
      " '0' '0' '2' '4' '8' '0' '0' '0' '0' '2' '0' '2' '0' '2' '0' '0' '8' '0'\n",
      " '6' '0' '14' '0' '0' '0' '0' '0' '4' '0' '0' '0' '4' '6' '0' '2' '0' '0'\n",
      " '4' '0' '6' '2' '0' '0' '8' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '12' '0' '0' '0' '0' '0' '12' '0' '0' '0' '12' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '12' '2' '0' '0' '0' '0' '4' '0'\n",
      " '2' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '4' '0' '0' '12' '0' '0' '10'\n",
      " '0' '0' '8' '0' '0' '2' '0' '0' '4' '0' '0' '0' '0' '0' '0' '0' '2' '0'\n",
      " '0' '6' '0' '6' '2' '0' '2' '2' '6' '0' '2' '0' '0' '0' '2' '0' '0' '0'\n",
      " '2' '0' '0' '8' '0' '0' '0' '10' '2' '0' '0' '0' '0' '0' '0' '0' '6' '0'\n",
      " '0' '14' '0' '6' '4' '14' '0' '0' '0' '6' '12' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '8' '0' '0' '0' '6' '8' '0' '0' '0' '0' '0' '0'\n",
      " '6' '0' '0' '0' '0' '4' '0' '0' '0' '0' '0' '2' '0' '4' '6' '0' '6' '0'\n",
      " '2' '0' '0' '0' '0' '2' '0' '0' '10' '8' '0' '0' '0' '0' '2' '4' '0' '0'\n",
      " '0' '12' '0' '0' '6' '0' '0' '8' '10' '0' '10' '2' '0' '0' '10' '4' '2'\n",
      " '0' '2' '0' '0' '0' '0' '0' '0' '2' '0' '4' '2' '0' '0' '6' '0' '2' '0'\n",
      " '0' '6' '0' '8' '14' '2' '0' '2' '0' '0' '0' '0' '0' '8' '0' '0' '0' '10'\n",
      " '2' '0' '0' '0' '0' '4' '0' '12' '0' '0' '0' '8' '0' '0' '0' '4' '0' '4'\n",
      " '0' '0' '0' '0' '0' '0' '6' '0' '0' '2' '0' '6' '0' '2' '0' '0' '8' '0'\n",
      " '0' '2' '0' '2' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '4' '0' '0' '4'\n",
      " '0' '2' '0' '0' '0' '0' '0' '0' '0' '2' '0' '6' '10' '0' '0' '4' '0' '0'\n",
      " '10' '0' '0' '0' '0' '0' '10' '0' '8' '0' '0' '16' '0' '0' '2' '0' '0'\n",
      " '4' '2' '0' '4' '0' '2' '2' '0' '4' '0' '0' '0' '8' '2' '2' '0' '4' '0'\n",
      " '0' '0' '0' '2' '0' '2' '0' '0' '2' '0' '0' '0' '2' '0' '0' '6' '0' '0'\n",
      " '0' '10' '0' '0' '0' '4' '2' '0' '0' '0' '0' '0' '0' '0' '0' '8' '2' '8'\n",
      " '0' '8' '12' '0' '0' '0' '0' '0' '0' '2' '0' '0' '2' '2' '0' '2' '8' '0'\n",
      " '0' '0' '0' '6' '0' '0' '0' '0' '0' '0' '6' '0' '0' '0' '8' '0' '2' '10'\n",
      " '0' '8' '12' '6' '0' '0' '0' '0' '2' '0' '0' '0' '6' '0' '8' '2' '0' '4'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '10' '0' '0' '2' '0' '8' '8' '0' '0' '0' '0' '8' '0' '0' '8' '0' '0'\n",
      " '2' '0' '0' '0' '0' '4' '0' '0' '2' '2' '8' '0' '4' '0' '0' '0' '0' '0'\n",
      " '0' '2' '0' '0' '2' '0' '0' '0' '2' '0' '2' '0' '6' '0' '2' '4' '4' '4'\n",
      " '2' '12' '0' '0' '0' '8' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '14' '2'\n",
      " '0' '0' '0' '0' '0' '0' '2' '2' '6' '0' '0' '0' '0' '0' '0' '2' '0' '0'\n",
      " '4' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '4' '0' '0' '0'\n",
      " '4' '0' '0' '0' '6' '0' '4' '2' '0' '2' '2' '0' '0' '0' '0' '4' '0' '0'\n",
      " '0' '0' '4' '0' '0' '10' '0' '0' '0' '0' '10' '0' '2' '0' '0' '4' '0' '0'\n",
      " '0' '0' '0' '0' '0' '2' '10' '0' '0' '0' '0' '0' '0' '0' '0' '12' '4' '0'\n",
      " '10' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '14' '0' '0' '0' '8'\n",
      " '12' '0' '0' '0' '2' '0' '0' '0' '6' '0' '8' '6' '0' '6' '0' '0' '12' '0'\n",
      " '0' '0' '0' '0' '0' '2' '0' '6' '0' '6' '0' '0' '0' '8' '0' '0' '0' '2'\n",
      " '0' '14' '2' '8' '16' '2' '12' '0' '8' '2' '0' '10' '0' '0' '0' '10' '0'\n",
      " '6' '0' '6' '4' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  offers.loc[:, string_col] = offers[string_col].astype(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_8080\\1972849651.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['2' '0' '2' '2' '0' '2' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '2' '0' '0' '0' '0' '0' '2' '0' '2' '0' '0' '2' '2' '2' '0' '0'\n",
      " '0' '0' '2' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '2' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '2' '0' '0' '2' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '2'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '2' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '2' '4' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '2' '0' '0' '0' '0' '4' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '2' '0' '0' '0' '2' '0' '0' '0' '0' '0' '2' '0' '2' '0' '0' '0' '0'\n",
      " '4' '2' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '2' '4' '0' '0' '0' '0'\n",
      " '0' '0' '0' '2' '0' '2' '2' '0' '2' '0' '0' '0' '0' '0' '2' '0' '0' '0'\n",
      " '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '2' '2' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '2' '0' '2' '0' '0' '0' '0'\n",
      " '0' '4' '0' '0' '0' '0' '0' '2' '2' '0' '2' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '4' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '0' '0' '2' '0' '0' '0' '0' '2' '0' '2' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '2' '0' '0' '2' '0' '4' '0' '0' '0' '0' '0' '0' '0' '2' '2' '0' '0'\n",
      " '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '2' '0' '0' '0'\n",
      " '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '2' '0' '2' '4' '0' '2' '0'\n",
      " '0' '0' '0' '0' '2' '2' '2' '0' '0' '0' '0' '0' '0' '0' '0' '4' '0' '0'\n",
      " '2' '0' '2' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0'\n",
      " '0' '2' '0' '2' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '2' '2' '2' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '2' '0' '0' '0' '2' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '2' '0' '0'\n",
      " '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '4'\n",
      " '0' '2' '0' '2' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '2' '0' '2' '0' '0' '0' '2' '0' '0' '0' '0' '0' '2' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '2' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '2' '0'\n",
      " '0' '0' '2' '0' '0' '2' '2' '2' '2' '0' '4' '0' '0' '0' '0' '0' '2' '0'\n",
      " '2' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '2' '4' '0' '2' '0' '2' '0' '2' '2' '0' '2' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '2' '4' '0' '0' '0' '0' '0' '0' '2' '2' '2'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2'\n",
      " '0' '2' '2' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '2' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '2'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '2' '4' '0' '0' '0' '0' '0' '0' '2' '0'\n",
      " '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  offers.loc[:, string_col] = offers[string_col].astype(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_8080\\1972849651.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '3' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '5' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '3'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '5' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '3'\n",
      " '0' '0' '0' '0' '5' '5' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0'\n",
      " '0' '0' '0' '0' '0' '0' '5' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '3' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '5' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '3' '0' '0' '0' '3' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  offers.loc[:, string_col] = offers[string_col].astype(str)\n"
     ]
    }
   ],
   "source": [
    "STRING_COLUMNS = ['rurality', 'offer uni preference', 'interview uni preference', 'deakin bonus', 'anu bonus',\n",
    "                  'mq bonus (gpa)', 'casper quartile', 'uq rmp tier']\n",
    "\n",
    "for string_col in STRING_COLUMNS:\n",
    "    offers.loc[:, string_col] = offers[string_col].astype(str)\n",
    "    offers.loc[:, string_col] = offers.replace('nan', 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers.to_csv(f\"{RELATIVE_OUT}/offer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(offers[\"interview uni\"] == UQ_NAME).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uq_mask(series):\n",
    "    return series.apply(lambda x: UQ_NAME in x if not pd.isna(x) else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rurality                    952\n",
       "s1 score                    952\n",
       "s2 score                    952\n",
       "s3 score                    952\n",
       "uw gamsat                   952\n",
       "w gamsat                    952\n",
       "offer uni                   688\n",
       "offer uni gpa               688\n",
       "offer uni gamsat            688\n",
       "offer uni place type        688\n",
       "offer uni preference        952\n",
       "interviewed?                688\n",
       "interview uni               385\n",
       "interview uni gpa           385\n",
       "interview uni gamsat        385\n",
       "places selected             720\n",
       "interview uni preference    952\n",
       "deakin bonus                952\n",
       "anu bonus                   952\n",
       "mq bonus (gpa)              952\n",
       "casper quartile             952\n",
       "uq rmp tier                 952\n",
       "gemsas over other?          688\n",
       "interview opinion           952\n",
       "notes                       567\n",
       "year                        952\n",
       "interview prep hours        509\n",
       "other rejections            142\n",
       "marker                      952\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers.apply(lambda x: x.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1533, 44)\n",
      "timestamp                object\n",
      "rurality                 object\n",
      "s1 score                  int64\n",
      "s2 score                  int64\n",
      "s3 score                  int64\n",
      "uw gamsat               float64\n",
      "w gamsat                float64\n",
      "deakin bonus              int64\n",
      "anu bonus                 int64\n",
      "mq bonus                  int64\n",
      "notes                    object\n",
      "interview?               object\n",
      "interview uni            object\n",
      "interview uni gpa       float64\n",
      "interview uni gamsat    float64\n",
      "pref 1 uni               object\n",
      "pref 1 gpa              float64\n",
      "pref 1 gamsat           float64\n",
      "pref 2 uni               object\n",
      "pref 2 gpa              float64\n",
      "pref 2 gamsat           float64\n",
      "pref 3 uni               object\n",
      "pref 3 gpa              float64\n",
      "pref 3 gamsat           float64\n",
      "pref 4 uni               object\n",
      "pref 4 gpa              float64\n",
      "pref 4 gamsat           float64\n",
      "pref 5 uni               object\n",
      "pref 5 gpa              float64\n",
      "pref 5 gamsat           float64\n",
      "pref 6 uni               object\n",
      "pref 6 gpa              float64\n",
      "pref 6 gamsat            object\n",
      "duplicates?              object\n",
      "year                      int64\n",
      "uq tier                  object\n",
      "casper quartile          object\n",
      "outlier                  object\n",
      "deakin tier              object\n",
      "unimelb gam              object\n",
      "undf bonuses             object\n",
      "unds bonuses             object\n",
      "location                 object\n",
      "uow bonuses             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "interview_raw = pd.read_csv(f\"{RELATIVE_IN}/interview.csv\", index_col=0)\n",
    "print(interview_raw.shape)\n",
    "print(interview_raw.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uw gamsat</th>\n",
       "      <th>w gamsat</th>\n",
       "      <th>interview uni gpa</th>\n",
       "      <th>interview uni gamsat</th>\n",
       "      <th>pref 1 gpa</th>\n",
       "      <th>pref 1 gamsat</th>\n",
       "      <th>pref 2 gpa</th>\n",
       "      <th>pref 2 gamsat</th>\n",
       "      <th>pref 3 gpa</th>\n",
       "      <th>pref 3 gamsat</th>\n",
       "      <th>pref 4 gpa</th>\n",
       "      <th>pref 4 gamsat</th>\n",
       "      <th>pref 5 gpa</th>\n",
       "      <th>pref 5 gamsat</th>\n",
       "      <th>pref 6 gpa</th>\n",
       "      <th>pref 6 gamsat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uw gamsat w gamsat interview uni gpa interview uni gamsat pref 1 gpa  \\\n",
       "0   float64  float64           float64              float64    float64   \n",
       "\n",
       "  pref 1 gamsat pref 2 gpa pref 2 gamsat pref 3 gpa pref 3 gamsat pref 4 gpa  \\\n",
       "0       float64    float64       float64    float64       float64    float64   \n",
       "\n",
       "  pref 4 gamsat pref 5 gpa pref 5 gamsat pref 6 gpa pref 6 gamsat  \n",
       "0       float64    float64       float64    float64        object  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_raw[[col for col in interview_raw.columns if \"gamsat\" in col or \"gpa\" in col]].dtypes.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1533\n",
      "568\n",
      "0\n",
      "568\n"
     ]
    }
   ],
   "source": [
    "print(interview_raw.shape[0])\n",
    "print(interview_raw[\"pref 6 gamsat\"].apply(lambda x: isinstance(x, str)).sum())\n",
    "print(interview_raw[\"pref 6 gamsat\"].apply(lambda x: isinstance(x, int)).sum())\n",
    "print(interview_raw[\"pref 6 gamsat\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>798</th>\n",
       "      <th>631</th>\n",
       "      <th>671</th>\n",
       "      <th>858</th>\n",
       "      <th>510</th>\n",
       "      <th>923</th>\n",
       "      <th>943</th>\n",
       "      <th>868</th>\n",
       "      <th>721</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pref 6 gamsat</th>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              798 631 671 858 510 923 943 868 721   365\n",
       "pref 6 gamsat  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  64.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_raw[\"pref 6 gamsat\"][interview_raw[\"pref 6 gamsat\"].notna()].sample(10).to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_raw[\"pref 6 gamsat\"] = interview_raw[\"pref 6 gamsat\"].apply(\n",
    "    lambda x: x.strip() if isinstance(x, str) else x\n",
    ")\n",
    "interview_raw[\"pref 6 gamsat\"] = pd.to_numeric(interview_raw[\"pref 6 gamsat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "[        nan 64.         63.66666667 62.66666667 66.5        67.75\n",
      " 63.33333333 66.         68.75       69.         63.5        68.25\n",
      " 71.25       69.5        70.         65.66666667 71.         63.\n",
      " 65.75       63.25       67.         65.         61.         69.75\n",
      " 56.75       61.75       68.         58.25       71.75       66.67\n",
      " 62.         64.67       62.33       65.33       70.33       64.25\n",
      " 62.67       68.5        62.75       65.67       62.25       59.\n",
      " 65.25       61.67       69.25       67.25       52.67       58.        ]\n"
     ]
    }
   ],
   "source": [
    "print(interview_raw[\"pref 6 gamsat\"].count())\n",
    "print(interview_raw[\"pref 6 gamsat\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switching to Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp               1533\n",
       "rurality                1533\n",
       "s1 score                1533\n",
       "s2 score                1533\n",
       "s3 score                1533\n",
       "uw gamsat               1532\n",
       "w gamsat                1533\n",
       "deakin bonus            1533\n",
       "anu bonus               1533\n",
       "mq bonus                1533\n",
       "notes                    821\n",
       "interview?              1004\n",
       "interview uni           1367\n",
       "interview uni gpa       1367\n",
       "interview uni gamsat    1367\n",
       "pref 1 uni               537\n",
       "pref 1 gpa               537\n",
       "pref 1 gamsat            537\n",
       "pref 2 uni               306\n",
       "pref 2 gpa               306\n",
       "pref 2 gamsat            306\n",
       "pref 3 uni               205\n",
       "pref 3 gpa               205\n",
       "pref 3 gamsat            205\n",
       "pref 4 uni               143\n",
       "pref 4 gpa               143\n",
       "pref 4 gamsat            143\n",
       "pref 5 uni               114\n",
       "pref 5 gpa               114\n",
       "pref 5 gamsat            114\n",
       "pref 6 uni                72\n",
       "pref 6 gpa                72\n",
       "pref 6 gamsat             72\n",
       "duplicates?              493\n",
       "year                    1533\n",
       "uq tier                  118\n",
       "casper quartile          671\n",
       "outlier                   17\n",
       "deakin tier               96\n",
       "unimelb gam              169\n",
       "undf bonuses              25\n",
       "unds bonuses               3\n",
       "location                  46\n",
       "uow bonuses              529\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'rurality', 's1 score', 's2 score', 's3 score',\n",
       "       'uw gamsat', 'w gamsat', 'deakin bonus', 'anu bonus', 'mq bonus',\n",
       "       'notes', 'interview?', 'interview uni', 'interview uni gpa',\n",
       "       'interview uni gamsat', 'pref 1 uni', 'pref 1 gpa', 'pref 1 gamsat',\n",
       "       'pref 2 uni', 'pref 2 gpa', 'pref 2 gamsat', 'pref 3 uni', 'pref 3 gpa',\n",
       "       'pref 3 gamsat', 'pref 4 uni', 'pref 4 gpa', 'pref 4 gamsat',\n",
       "       'pref 5 uni', 'pref 5 gpa', 'pref 5 gamsat', 'pref 6 uni', 'pref 6 gpa',\n",
       "       'pref 6 gamsat', 'duplicates?', 'year', 'uq tier', 'casper quartile',\n",
       "       'outlier', 'deakin tier', 'unimelb gam', 'undf bonuses', 'unds bonuses',\n",
       "       'location', 'uow bonuses'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_8080\\1990756901.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '2' '0' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  interview_raw.loc[:, string_col] = interview_raw[string_col].astype(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_8080\\1990756901.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '4' '0' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  interview_raw.loc[:, string_col] = interview_raw[string_col].astype(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_8080\\1990756901.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  interview_raw.loc[:, string_col] = interview_raw[string_col].astype(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_8080\\1990756901.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['nan' 'nan' 'nan' ... '0.0' '0.0' '0.0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  interview_raw.loc[:, string_col] = interview_raw[string_col].astype(str)\n"
     ]
    }
   ],
   "source": [
    "STRING_COLUMNS = ['deakin bonus', 'anu bonus', 'mq bonus', 'uq tier', 'casper quartile', 'deakin tier', \n",
    "                  'unimelb gam', 'undf bonuses', 'unds bonuses', 'uow bonuses']\n",
    "\n",
    "for string_col in STRING_COLUMNS:\n",
    "    interview_raw.loc[:, string_col] = interview_raw[string_col].astype(str)\n",
    "    interview_raw.loc[:, string_col] = offers.replace('nan', 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing UQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNI_COLUMNS = [\"interview uni\"] + [f\"pref {i+1} uni\" for i in range(6)]\n",
    "UQ_NAME = \"The University of Queensland\"\n",
    "RMP_ENDINGS = [\"(DD MP)\", \"(CQ-WB RMP)\", \"(RMP/DDMP)\"]\n",
    "METRO_ENDING = \"(Greater Brisbane)\"\n",
    "\n",
    "# fixing the queensland column\n",
    "interview = interview_raw.copy()\n",
    "\n",
    "# change the MD and WB to correct types\n",
    "for uni_column in UNI_COLUMNS:\n",
    "    interview.loc[interview[uni_column].isin([f\"{UQ_NAME} {x}\" for x in RMP_ENDINGS ]), uni_column] = f\"{UQ_NAME} (RMP)\"\n",
    "    interview.loc[interview[uni_column] == f\"{UQ_NAME} {METRO_ENDING}\", uni_column] = f\"{UQ_NAME} (Metro)\"\n",
    "\n",
    "# make the notes lowe case\n",
    "interview.loc[:, \"notes\"] = interview[\"notes\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interview uni\n",
       "The University of Melbourne               300\n",
       "The University of Notre Dame Sydney       198\n",
       "Deakin University                         126\n",
       "Griffith University                       110\n",
       "The University of Western Australia       108\n",
       "The University of Notre Dame Fremantle    101\n",
       "The University of Wollongong               93\n",
       "The University of Queensland (RMP)         83\n",
       "The University of Queensland               74\n",
       "Australian National University             62\n",
       "The University of Queensland (Metro)       60\n",
       "Macquarie University                       52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#interview.groupby(\"interview uni\")[\"year\"].value_counts()\n",
    "interview[\"interview uni\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "interview.to_csv(f\"{RELATIVE_OUT}/interview.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
