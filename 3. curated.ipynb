{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATIVE_IN = \"2. raw\"\n",
    "RELATIVE_OUT = \"3. curated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(952, 31)\n"
     ]
    }
   ],
   "source": [
    "offers_raw = pd.read_csv(f\"{RELATIVE_IN}/offers.csv\", index_col=0)\n",
    "print(offers_raw.shape)\n",
    "#print(offers_raw.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offer uni\n",
       "The University of Melbourne                        163\n",
       "Deakin University                                  104\n",
       "Griffith University                                 84\n",
       "The University of Western Australia                 61\n",
       "The University of Notre Dame Sydney                 54\n",
       "The University of Notre Dame Fremantle              51\n",
       "Australian National University                      32\n",
       "The University of Queensland (CQ-WB RMP)            30\n",
       "The University of Queensland                        29\n",
       "The University of Wollongong                        27\n",
       "Macquarie University                                27\n",
       "The University of Queensland (Greater Brisbane)     14\n",
       "The University of Queensland (DD MP)                12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_raw[\"offer uni\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "UQ_NAME = \"The University of Queensland\"\n",
    "RMP_ENDINGS = [\"(DD MP)\", \"(CQ-WB RMP)\"]\n",
    "METRO_ENDING = \"(Greater Brisbane)\"\n",
    "\n",
    "# fixing the queensland column\n",
    "offers = offers_raw.copy()\n",
    "\n",
    "# get the RMP types\n",
    "offers.loc[offers[\"uq type\"] == \"RMP\", \"offer uni\"] = UQ_NAME + \" (RMP)\"\n",
    "\n",
    "# change the MD and WB to correct types\n",
    "offers.loc[offers[\"offer uni\"].isin([f\"{UQ_NAME} {x}\" for x in RMP_ENDINGS ]), \"offer uni\"] = UQ_NAME + \" (RMP)\"\n",
    "offers.loc[offers[\"interview uni\"].isin([f\"{UQ_NAME} {x}\" for x in RMP_ENDINGS ]), \"interview uni\"] = UQ_NAME + \" (RMP)\"\n",
    "\n",
    "# change greater brisbance\n",
    "metro_mask_offer = (offers[\"offer uni\"] == UQ_NAME) | (offers[\"offer uni\"] == f\"{UQ_NAME} {METRO_ENDING}\")\n",
    "metro_mask_interview = (offers[\"interview uni\"] == UQ_NAME) | (offers[\"interview uni\"] == f\"{UQ_NAME} {METRO_ENDING}\")\n",
    "offers.loc[metro_mask_offer, \"offer uni\"] = f\"{UQ_NAME} (Metro)\"\n",
    "offers.loc[metro_mask_interview, \"interview uni\"] = f\"{UQ_NAME} (Metro)\"\n",
    "\n",
    "# dropping the type\n",
    "offers.drop(columns=\"uq type\", inplace=True)\n",
    "\n",
    "# fixing the interview column\n",
    "offers.loc[(offers[\"year\"] == 2023) & (offers[\"interview uni\"].isna()), \"interviewed?\"] = \"Yes\"\n",
    "offers.loc[(offers[\"year\"] == 2023) & (offers[\"interview uni\"].notna() & (offers[\"offer uni\"].notna())), \"interviewed?\"] = \"No\"\n",
    "\n",
    "# make the notes lowe case\n",
    "offers.loc[:, \"notes\"] = offers[\"notes\"].str.lower()\n",
    "\n",
    "# drop un necessary columns\n",
    "offers.drop(columns=[\"status\", \"timestamp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offer uni\n",
       "The University of Melbourne               163\n",
       "Deakin University                         104\n",
       "Griffith University                        84\n",
       "The University of Queensland (RMP)         61\n",
       "The University of Western Australia        61\n",
       "The University of Notre Dame Sydney        54\n",
       "The University of Notre Dame Fremantle     51\n",
       "Australian National University             32\n",
       "The University of Wollongong               27\n",
       "Macquarie University                       27\n",
       "The University of Queensland (Metro)       24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers[\"offer uni\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the marker type column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 28)\n",
      "(264, 28)\n",
      "(264, 28)\n",
      "(0, 28)\n"
     ]
    }
   ],
   "source": [
    "print(offers[(offers[\"offer uni place type\"].isna()) & (offers[\"offer uni\"].isna())].shape)  # offer uni and offer uni type notna\n",
    "print(offers[(offers[\"offer uni\"].isna())].shape)                                            # offer uni notna\n",
    "print(offers[(offers[\"offer uni place type\"].isna())].shape)                                 # offer uni type notna\n",
    "\n",
    "print(offers[(offers[\"offer uni\"].isna()) & (offers[\"places selected\"].isna())].shape)       # offer uni na with places selected also na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "places selected\n",
       "CSP, BMP          327\n",
       "CSP, BMP, FFP     119\n",
       "All                94\n",
       "CSP & BMP Only     88\n",
       "CSP                47\n",
       "CSP Only           29\n",
       "FFP                 5\n",
       "BMP                 5\n",
       "CSP, FFP            5\n",
       "BMP, FFP            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers[\"places selected\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "places selected\n",
       "[CSP, BMP]         415\n",
       "[CSP, BMP, FFP]    213\n",
       "[CSP]               76\n",
       "[FFP]                5\n",
       "[BMP]                5\n",
       "[CSP, FFP]           5\n",
       "[BMP, FFP]           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixing the places selected column with dictionary\n",
    "CSP = \"CSP\"\n",
    "BMP = \"BMP\"\n",
    "FFP = \"FFP\"\n",
    "\n",
    "rename_places_selected = {\n",
    "    \"CSP, BMP\": [CSP, BMP],\n",
    "    \"CSP & BMP Only\": [CSP, BMP],\n",
    "\n",
    "    \"CSP, BMP, FFP\": [CSP, BMP, FFP],\n",
    "    \"All\": [CSP, BMP, FFP],\n",
    "\n",
    "    \"CSP\": [CSP],\n",
    "    \"CSP Only\": [CSP],\n",
    "    \"CSP, FFP\": [CSP, FFP],\n",
    "    \n",
    "    \"BMP\": [BMP],\n",
    "    \"BMP, FFP\": [BMP, FFP],\n",
    "\n",
    "    \"FFP\": [FFP],\n",
    "}\n",
    "\n",
    "offers[\"places selected\"] = offers[\"places selected\"].apply(lambda x: rename_places_selected[x] \n",
    "                                                            if (not pd.isna(x)) and (rename_places_selected.get(x)) else x)\n",
    "\n",
    "offers[\"places selected\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offer uni place type\n",
       "CSP    491\n",
       "BMP    131\n",
       "FFP     66\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers['offer uni place type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks how many times someone gets rejected and the places they selected aren't recorded\n",
    "offers[offers[\"places selected\"].isna()][\"interview uni\"].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers[\"marker\"] = offers[\"offer uni place type\"]\n",
    "offers.loc[offers[\"marker\"].isna(), \"marker\"] = offers[\"places selected\"]\n",
    "#offers.loc[offers[\"marker\"].isna(), \"marker\"] = \"Unknown\"\n",
    "offers[\"marker\"].isna().sum()\n",
    "\n",
    "#offers[\"marker\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_1504\\2049269939.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' 'nan'\n",
      " '1.0' '1.0' '3.0' '1.0' 'nan' '4.0' '3.0' '1.0' '1.0' '5.0' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' '5.0' '2.0' 'nan' '1.0'\n",
      " '1.0' '1.0' 'nan' 'nan' '1.0' '1.0' 'nan' '1.0' '4.0' 'nan' 'nan' 'nan'\n",
      " 'nan' '1.0' 'nan' 'nan' 'nan' '1.0' '1.0' 'nan' '1.0' '4.0' '1.0' '1.0'\n",
      " 'nan' '1.0' '1.0' '2.0' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' '2.0' '1.0'\n",
      " 'nan' '1.0' 'nan' '2.0' 'nan' 'nan' '2.0' '2.0' '1.0' 'nan' '1.0' '1.0'\n",
      " '2.0' 'nan' 'nan' 'nan' '1.0' '2.0' 'nan' '1.0' 'nan' 'nan' '1.0' '1.0'\n",
      " '1.0' 'nan' '1.0' '1.0' 'nan' '1.0' '1.0' '1.0' 'nan' '1.0' '1.0' 'nan'\n",
      " '1.0' '2.0' '2.0' '2.0' 'nan' '1.0' '1.0' '1.0' '1.0' '2.0' '1.0' '3.0'\n",
      " '1.0' '2.0' 'nan' '1.0' '1.0' '1.0' 'nan' '1.0' 'nan' '1.0' 'nan' 'nan'\n",
      " 'nan' '2.0' '6.0' '2.0' '1.0' 'nan' 'nan' 'nan' '1.0' '1.0' '2.0' '2.0'\n",
      " '1.0' '2.0' '1.0' '1.0' '3.0' '1.0' '1.0' '1.0' 'nan' '2.0' '2.0' '1.0'\n",
      " 'nan' '1.0' 'nan' '1.0' '1.0' '1.0' '2.0' '1.0' '2.0' '1.0' 'nan' '1.0'\n",
      " '3.0' 'nan' '1.0' '1.0' '2.0' '2.0' '3.0' '1.0' '1.0' '1.0' '1.0' '2.0'\n",
      " '2.0' '1.0' '1.0' 'nan' '2.0' 'nan' '1.0' '1.0' '1.0' '2.0' '1.0' 'nan'\n",
      " '5.0' '1.0' '1.0' '4.0' '1.0' 'nan' '1.0' 'nan' '1.0' '1.0' '1.0' '6.0'\n",
      " '2.0' 'nan' 'nan' '1.0' '2.0' '1.0' 'nan' '1.0' 'nan' '1.0' '1.0' '2.0'\n",
      " '3.0' '1.0' '1.0' '3.0' 'nan' '1.0' '1.0' '2.0' '2.0' 'nan' '1.0' 'nan'\n",
      " '1.0' 'nan' '1.0' '3.0' '1.0' '1.0' 'nan' '2.0' '1.0' 'nan' '4.0' '1.0'\n",
      " 'nan' 'nan' 'nan' '1.0' '1.0' '1.0' '1.0' '1.0' '5.0' 'nan' 'nan' '3.0'\n",
      " '2.0' '2.0' 'nan' '2.0' '1.0' '1.0' '1.0' 'nan' '1.0' '1.0' 'nan' '2.0'\n",
      " '1.0' 'nan' '2.0' '1.0' '4.0' '1.0' '1.0' '1.0' '1.0' '1.0' '1.0' '2.0'\n",
      " 'nan' '1.0' '1.0' '1.0' '1.0' '3.0' 'nan' '1.0' '6.0' '1.0' '1.0' '1.0'\n",
      " '1.0' 'nan' 'nan' '2.0' '1.0' '1.0' '1.0' '1.0' 'nan' '1.0' '2.0' '3.0'\n",
      " '2.0' '4.0' '2.0' 'nan' '1.0' '1.0' '1.0' '6.0' '2.0' 'nan' '1.0' '1.0'\n",
      " 'nan' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan' '1.0' 'nan' '1.0' 'nan' '1.0'\n",
      " 'nan' '1.0' '1.0' 'nan' '1.0' '4.0' '1.0' '5.0' 'nan' '1.0' '1.0' 'nan'\n",
      " '1.0' '2.0' 'nan' 'nan' '4.0' 'nan' '3.0' 'nan' '1.0' '5.0' 'nan' '3.0'\n",
      " '1.0' '3.0' '1.0' 'nan' 'nan' '1.0' '4.0' 'nan' '6.0' '4.0' '1.0' '1.0'\n",
      " '1.0' '3.0' '3.0' '5.0' '1.0' '4.0' '1.0' '1.0' '3.0' '2.0' '1.0' '2.0'\n",
      " '1.0' '1.0' '1.0' 'nan' '1.0' '1.0' '3.0' '3.0' '1.0' '4.0' 'nan' 'nan'\n",
      " '3.0' '1.0' '1.0' 'nan' 'nan' 'nan' '1.0' '3.0' 'nan' 'nan' '1.0' '1.0'\n",
      " '2.0' 'nan' '1.0' 'nan' 'nan' '1.0' '1.0' '2.0' '1.0' '1.0' '2.0' '1.0'\n",
      " '1.0' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' '2.0' 'nan'\n",
      " '4.0' 'nan' 'nan' '3.0' 'nan' 'nan' 'nan' '3.0' '1.0' '1.0' 'nan' 'nan'\n",
      " '1.0' 'nan' 'nan' 'nan' '6.0' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan'\n",
      " 'nan' '3.0' '2.0' 'nan' 'nan' 'nan' '4.0' 'nan' 'nan' '1.0' '1.0' 'nan'\n",
      " '1.0' '6.0' '1.0' 'nan' '2.0' 'nan' '1.0' '1.0' 'nan' '1.0' '1.0' '2.0'\n",
      " '1.0' 'nan' 'nan' 'nan' '1.0' '1.0' '1.0' 'nan' 'nan' 'nan' '1.0' '1.0'\n",
      " '3.0' 'nan' '1.0' '5.0' 'nan' '1.0' '5.0' 'nan' '1.0' '2.0' 'nan' 'nan'\n",
      " '1.0' '3.0' '1.0' '1.0' '3.0' '3.0' '1.0' '3.0' 'nan' 'nan' 'nan' 'nan'\n",
      " '2.0' 'nan' '1.0' '1.0' '1.0' 'nan' '1.0' 'nan' '1.0' '5.0' '1.0' '3.0'\n",
      " '4.0' 'nan' '1.0' '1.0' '1.0' 'nan' '1.0' 'nan' '3.0' '1.0' '3.0' '1.0'\n",
      " '1.0' '1.0' '1.0' 'nan' '1.0' '1.0' '1.0' '1.0' '1.0' '1.0' '3.0' '2.0'\n",
      " '3.0' '1.0' '1.0' '1.0' 'nan' '3.0' 'nan' '1.0' '1.0' 'nan' '1.0' 'nan'\n",
      " '1.0' '1.0' '1.0' '1.0' '1.0' '6.0' '4.0' '1.0' 'nan' '1.0' '1.0' '1.0'\n",
      " '1.0' '2.0' '3.0' 'nan' '2.0' '1.0' '1.0' '1.0' '1.0' '1.0' '2.0' '1.0'\n",
      " '1.0' '1.0' '3.0' 'nan' 'nan' '2.0' '1.0' '1.0' '1.0' '1.0' 'nan' 'nan'\n",
      " 'nan' '1.0' '1.0' 'nan' '1.0' '5.0' 'nan' '1.0' '1.0' '2.0' '4.0' '1.0'\n",
      " 'nan' 'nan' '1.0' '1.0' '1.0' '2.0' 'nan' '1.0' 'nan' '1.0' '2.0' 'nan'\n",
      " '1.0' '1.0' '2.0' '1.0' '2.0' 'nan' '1.0' 'nan' '4.0' '1.0' '1.0' '1.0'\n",
      " '1.0' '4.0' '1.0' 'nan' '1.0' '1.0' '1.0' '1.0' '4.0' '1.0' 'nan' '1.0'\n",
      " '1.0' '2.0' 'nan' '1.0' '1.0' '2.0' '1.0' '1.0' '1.0' '3.0' '1.0' '1.0'\n",
      " '1.0' '1.0' 'nan' '3.0' '1.0' '1.0' 'nan' '5.0' '1.0' '1.0' '1.0' '1.0'\n",
      " '1.0' '2.0' '1.0' '1.0' '1.0' '1.0' '1.0' '3.0' '1.0' '3.0' '1.0' '1.0'\n",
      " '1.0' '1.0' '1.0' '1.0' '1.0' '1.0' '1.0' '2.0' '3.0' '1.0' '1.0' '1.0'\n",
      " '3.0' '1.0' '1.0' '1.0' '1.0' 'nan' 'nan' '2.0' '1.0' '5.0' '1.0' '2.0'\n",
      " '4.0' '3.0' 'nan' 'nan' '4.0' '1.0' '1.0' '1.0' '1.0' 'nan' '1.0' '1.0'\n",
      " '3.0' 'nan' '4.0' 'nan' '4.0' '1.0' '6.0' '1.0' '1.0' '1.0' '3.0' '6.0'\n",
      " '1.0' '1.0' 'nan' '1.0' '1.0' '1.0' '3.0' 'nan' '1.0' '1.0' '1.0' 'nan'\n",
      " '3.0' 'nan' 'nan' '2.0' 'nan' '2.0' 'nan' '1.0' '1.0' '4.0' '1.0' 'nan'\n",
      " '2.0' '1.0' 'nan' '5.0' '1.0' '5.0' '1.0' '2.0' 'nan' '1.0' '2.0' '2.0'\n",
      " 'nan' '1.0' '2.0' '4.0' '3.0' '1.0' '3.0' '1.0' '3.0' '1.0' 'nan' '2.0'\n",
      " '1.0' '1.0' '3.0' '1.0' 'nan' '2.0' '2.0' '1.0' '1.0' '1.0' '1.0' '4.0'\n",
      " '1.0' 'nan' '1.0' 'nan' '1.0' '1.0' 'nan' '1.0' '1.0' '1.0' '5.0' '4.0'\n",
      " '2.0' '1.0' '1.0' '1.0' '1.0' '1.0' '5.0' 'nan' 'nan' 'nan' '1.0' 'nan'\n",
      " '4.0' '1.0' '5.0' '1.0' 'nan' '1.0' '2.0' '1.0' '1.0' '1.0' '1.0' '2.0'\n",
      " '1.0' '3.0' '1.0' '2.0' 'nan' '2.0' '4.0' '2.0' 'nan' '1.0' '2.0' '1.0'\n",
      " '3.0' '6.0' '1.0' '1.0' '1.0' '4.0' '6.0' 'nan' '3.0' '1.0' '1.0' '1.0'\n",
      " '1.0' '1.0' '4.0' 'nan' '1.0' '3.0' '1.0' '1.0' 'nan' '1.0' '3.0' '1.0'\n",
      " '2.0' '1.0' '2.0' '3.0' '2.0' '4.0' 'nan' '3.0' '2.0' 'nan' '1.0' '1.0'\n",
      " '1.0' '3.0' '1.0' '1.0' '1.0' 'nan' '1.0' '1.0' 'nan' '1.0' '1.0' '2.0'\n",
      " '2.0' '1.0' 'nan' 'nan' '6.0' '1.0' '4.0' '4.0' '1.0' 'nan' '1.0' '1.0'\n",
      " '1.0' 'nan' '1.0' 'nan' '1.0' 'nan' '1.0' '1.0' 'nan' '2.0' '1.0' '1.0'\n",
      " '1.0' '1.0' '1.0' '3.0' '2.0' '1.0' '1.0' '5.0' '1.0' '1.0' 'nan' '1.0'\n",
      " '1.0' 'nan' 'nan' '6.0' '5.0' 'nan' '4.0' '1.0' '1.0' '1.0' '1.0' '3.0'\n",
      " '4.0' 'nan' 'nan' 'nan' '1.0' '1.0' '3.0' '2.0' '2.0' '1.0' '6.0' '1.0'\n",
      " '1.0' '1.0' '5.0' 'nan' '2.0' '1.0' '6.0' '1.0' '4.0' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' '1.0' '1.0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  offers.loc[:, string_col] = offers[string_col].astype(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_1504\\2049269939.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['1.0' 'nan' '5.0' '1.0' '5.0' '1.0' '2.0' 'nan' '1.0' '1.0' '1.0' '4.0'\n",
      " 'nan' 'nan' '1.0' 'nan' '4.0' 'nan' '2.0' 'nan' 'nan' 'nan' '1.0' '1.0'\n",
      " '2.0' '1.0' '1.0' '1.0' 'nan' '1.0' '4.0' '1.0' '4.0' '1.0' '1.0' 'nan'\n",
      " 'nan' 'nan' '2.0' '1.0' 'nan' 'nan' '1.0' 'nan' '3.0' '5.0' '5.0' '1.0'\n",
      " '2.0' 'nan' '2.0' '1.0' '1.0' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan'\n",
      " '1.0' 'nan' 'nan' '1.0' 'nan' 'nan' '3.0' '1.0' '1.0' '1.0' '1.0' 'nan'\n",
      " '6.0' 'nan' '1.0' '1.0' '1.0' '5.0' '1.0' '1.0' 'nan' '1.0' 'nan' 'nan'\n",
      " '1.0' '1.0' '1.0' '1.0' 'nan' 'nan' '1.0' 'nan' '1.0' '1.0' 'nan' 'nan'\n",
      " 'nan' '1.0' 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' '2.0'\n",
      " 'nan' '1.0' '1.0' '1.0' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' '3.0' 'nan' 'nan' 'nan' '1.0' 'nan' '2.0' 'nan' '1.0' '1.0'\n",
      " '1.0' '1.0' '2.0' '1.0' 'nan' '1.0' '1.0' '1.0' 'nan' 'nan' '1.0' 'nan'\n",
      " 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan'\n",
      " '6.0' 'nan' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan'\n",
      " '2.0' '2.0' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' 'nan' '5.0' 'nan' '1.0' 'nan' 'nan' 'nan' '1.0' 'nan' '3.0'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan' 'nan' 'nan' '6.0'\n",
      " '1.0' '2.0' '1.0' 'nan' '1.0' 'nan' '1.0' 'nan' '1.0' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' '1.0' '3.0' 'nan' '1.0'\n",
      " 'nan' '5.0' 'nan' '2.0' 'nan' 'nan' '1.0' 'nan' 'nan' '2.0' '3.0' 'nan'\n",
      " '1.0' '1.0' '3.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' '6.0' '3.0' 'nan'\n",
      " 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' '2.0' 'nan' 'nan' '1.0' 'nan'\n",
      " 'nan' '3.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '4.0' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' '1.0' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' '3.0' 'nan' 'nan' '2.0'\n",
      " '1.0' '3.0' 'nan' '3.0' 'nan' 'nan' 'nan' '1.0' '1.0' '6.0' 'nan' 'nan'\n",
      " '1.0' '1.0' '1.0' 'nan' '1.0' 'nan' '5.0' 'nan' '1.0' 'nan' '1.0' 'nan'\n",
      " '2.0' 'nan' 'nan' '3.0' 'nan' '1.0' 'nan' '1.0' '6.0' 'nan' 'nan' '2.0'\n",
      " 'nan' '1.0' '2.0' '1.0' 'nan' '1.0' '2.0' '1.0' 'nan' '2.0' '1.0' 'nan'\n",
      " 'nan' '2.0' 'nan' '2.0' '2.0' 'nan' '3.0' '2.0' '2.0' 'nan' 'nan' 'nan'\n",
      " 'nan' '1.0' '1.0' 'nan' 'nan' '1.0' 'nan' 'nan' '2.0' '1.0' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' '1.0' 'nan' '3.0' '1.0' '1.0'\n",
      " '1.0' 'nan' 'nan' '1.0' '1.0' '4.0' 'nan' 'nan' '1.0' '1.0' 'nan' 'nan'\n",
      " 'nan' '2.0' 'nan' '1.0' '1.0' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' '1.0' 'nan' 'nan' '1.0' '5.0' '2.0' '2.0' '1.0' 'nan' '1.0' '1.0'\n",
      " '3.0' '2.0' '3.0' '1.0' '6.0' '3.0' '1.0' '2.0' 'nan' 'nan' '4.0' '1.0'\n",
      " 'nan' '1.0' '2.0' '4.0' 'nan' '3.0' '1.0' '1.0' '1.0' 'nan' '2.0' '1.0'\n",
      " '3.0' 'nan' '1.0' '1.0' '1.0' '1.0' '2.0' '1.0' '1.0' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' 'nan' '1.0' 'nan' '2.0' 'nan' 'nan' '1.0' 'nan' 'nan' '1.0'\n",
      " 'nan' '5.0' '1.0' '1.0' 'nan' 'nan' 'nan' '1.0' '1.0' '1.0' 'nan' 'nan'\n",
      " 'nan' '3.0' 'nan' '1.0' '2.0' 'nan' '2.0' '1.0' 'nan' 'nan' '1.0' '1.0'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' '1.0' '1.0' '5.0'\n",
      " 'nan' '1.0' 'nan' 'nan' 'nan' '6.0' 'nan' '2.0' 'nan' 'nan' 'nan' '1.0'\n",
      " '3.0' '2.0' 'nan' 'nan' 'nan' '2.0' 'nan' '1.0' '2.0' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan' 'nan' '1.0' 'nan' '1.0'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' '2.0' '2.0' 'nan' '3.0' 'nan' 'nan' 'nan'\n",
      " 'nan' '1.0' '1.0' '3.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' '1.0'\n",
      " '1.0' 'nan' 'nan' '6.0' 'nan' '4.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " '2.0' '1.0' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' '1.0' 'nan' '1.0' '1.0' 'nan' '1.0' '3.0' 'nan' 'nan' 'nan'\n",
      " 'nan' '1.0' 'nan' '3.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '3.0' 'nan'\n",
      " 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '2.0' 'nan' 'nan'\n",
      " 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " '2.0' 'nan' 'nan' 'nan' 'nan' '1.0' '3.0' 'nan' 'nan' '1.0' 'nan' 'nan'\n",
      " '3.0' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan'\n",
      " '1.0' '3.0' 'nan' '2.0' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' '5.0'\n",
      " 'nan' '1.0' '6.0' 'nan' '1.0' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' '1.0'\n",
      " 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' '1.0'\n",
      " '1.0' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0'\n",
      " 'nan' '1.0' 'nan' '1.0' 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '2.0' '1.0' '2.0' 'nan' '1.0'\n",
      " 'nan' 'nan' '4.0' 'nan' '3.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' '2.0' '2.0' 'nan' 'nan' 'nan'\n",
      " 'nan' 'nan' '3.0' '1.0' 'nan' 'nan' 'nan' 'nan' '4.0' 'nan' '1.0' 'nan'\n",
      " '1.0' 'nan' '1.0' '1.0' '1.0' '1.0' '1.0' '1.0' 'nan' '1.0' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan'\n",
      " '1.0' 'nan' '1.0' '1.0' '1.0' 'nan' '1.0' 'nan' 'nan' '1.0' 'nan' 'nan'\n",
      " 'nan' '1.0' 'nan' '3.0' 'nan' '1.0' 'nan' 'nan' '1.0' '1.0' 'nan' 'nan'\n",
      " 'nan' 'nan' 'nan' '1.0' 'nan' 'nan' 'nan' '4.0' 'nan' 'nan' '1.0' 'nan'\n",
      " 'nan' '4.0' '2.0' '2.0' '3.0' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      " '2.0' '1.0' '4.0' '1.0' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan' '4.0' 'nan'\n",
      " 'nan' 'nan' '2.0' '1.0' '1.0' 'nan' 'nan' 'nan' '1.0' '2.0' '1.0' '3.0'\n",
      " '2.0' '1.0' 'nan' '5.0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  offers.loc[:, string_col] = offers[string_col].astype(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_1504\\2049269939.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['2' '0' '2' '2' '0' '0' '0' '6' '2' '0' '0' '0' '8' '6' '0' '0' '0' '2'\n",
      " '4' '2' '10' '0' '0' '0' '2' '0' '2' '0' '4' '2' '2' '0' '2' '0' '0' '0'\n",
      " '6' '10' '0' '0' '0' '8' '0' '0' '0' '0' '0' '0' '0' '0' '4' '0' '0' '0'\n",
      " '10' '0' '0' '0' '10' '14' '0' '8' '0' '0' '2' '0' '0' '0' '0' '0' '0'\n",
      " '0' '2' '8' '0' '2' '6' '0' '0' '4' '12' '2' '8' '2' '0' '2' '0' '2' '0'\n",
      " '0' '0' '0' '0' '0' '4' '0' '0' '0' '0' '0' '6' '4' '0' '0' '0' '0' '0'\n",
      " '0' '4' '0' '0' '0' '0' '10' '8' '0' '6' '2' '2' '0' '2' '0' '0' '0' '0'\n",
      " '12' '2' '0' '2' '10' '6' '10' '0' '0' '0' '0' '6' '0' '2' '8' '0' '8'\n",
      " '8' '0' '0' '0' '0' '2' '0' '8' '2' '6' '0' '0' '0' '14' '0' '4' '12' '0'\n",
      " '4' '2' '8' '0' '0' '0' '0' '14' '0' '0' '0' '0' '0' '0' '0' '0' '0' '4'\n",
      " '0' '6' '0' '2' '2' '0' '2' '2' '0' '12' '8' '2' '8' '0' '2' '8' '0' '0'\n",
      " '0' '0' '0' '0' '0' '12' '0' '0' '4' '0' '0' '2' '0' '0' '0' '0' '2' '0'\n",
      " '0' '0' '2' '4' '8' '0' '0' '0' '0' '2' '0' '2' '0' '2' '0' '0' '8' '0'\n",
      " '6' '0' '14' '0' '0' '0' '0' '0' '4' '0' '0' '0' '4' '6' '0' '2' '0' '0'\n",
      " '4' '0' '6' '2' '0' '0' '8' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '12' '0' '0' '0' '0' '0' '12' '0' '0' '0' '12' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '12' '2' '0' '0' '0' '0' '4' '0'\n",
      " '2' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '4' '0' '0' '12' '0' '0' '10'\n",
      " '0' '0' '8' '0' '0' '2' '0' '0' '4' '0' '0' '0' '0' '0' '0' '0' '2' '0'\n",
      " '0' '6' '0' '6' '2' '0' '2' '2' '6' '0' '2' '0' '0' '0' '2' '0' '0' '0'\n",
      " '2' '0' '0' '8' '0' '0' '0' '10' '2' '0' '0' '0' '0' '0' '0' '0' '6' '0'\n",
      " '0' '14' '0' '6' '4' '14' '0' '0' '0' '6' '12' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '8' '0' '0' '0' '6' '8' '0' '0' '0' '0' '0' '0'\n",
      " '6' '0' '0' '0' '0' '4' '0' '0' '0' '0' '0' '2' '0' '4' '6' '0' '6' '0'\n",
      " '2' '0' '0' '0' '0' '2' '0' '0' '10' '8' '0' '0' '0' '0' '2' '4' '0' '0'\n",
      " '0' '12' '0' '0' '6' '0' '0' '8' '10' '0' '10' '2' '0' '0' '10' '4' '2'\n",
      " '0' '2' '0' '0' '0' '0' '0' '0' '2' '0' '4' '2' '0' '0' '6' '0' '2' '0'\n",
      " '0' '6' '0' '8' '14' '2' '0' '2' '0' '0' '0' '0' '0' '8' '0' '0' '0' '10'\n",
      " '2' '0' '0' '0' '0' '4' '0' '12' '0' '0' '0' '8' '0' '0' '0' '4' '0' '4'\n",
      " '0' '0' '0' '0' '0' '0' '6' '0' '0' '2' '0' '6' '0' '2' '0' '0' '8' '0'\n",
      " '0' '2' '0' '2' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '4' '0' '0' '4'\n",
      " '0' '2' '0' '0' '0' '0' '0' '0' '0' '2' '0' '6' '10' '0' '0' '4' '0' '0'\n",
      " '10' '0' '0' '0' '0' '0' '10' '0' '8' '0' '0' '16' '0' '0' '2' '0' '0'\n",
      " '4' '2' '0' '4' '0' '2' '2' '0' '4' '0' '0' '0' '8' '2' '2' '0' '4' '0'\n",
      " '0' '0' '0' '2' '0' '2' '0' '0' '2' '0' '0' '0' '2' '0' '0' '6' '0' '0'\n",
      " '0' '10' '0' '0' '0' '4' '2' '0' '0' '0' '0' '0' '0' '0' '0' '8' '2' '8'\n",
      " '0' '8' '12' '0' '0' '0' '0' '0' '0' '2' '0' '0' '2' '2' '0' '2' '8' '0'\n",
      " '0' '0' '0' '6' '0' '0' '0' '0' '0' '0' '6' '0' '0' '0' '8' '0' '2' '10'\n",
      " '0' '8' '12' '6' '0' '0' '0' '0' '2' '0' '0' '0' '6' '0' '8' '2' '0' '4'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '10' '0' '0' '2' '0' '8' '8' '0' '0' '0' '0' '8' '0' '0' '8' '0' '0'\n",
      " '2' '0' '0' '0' '0' '4' '0' '0' '2' '2' '8' '0' '4' '0' '0' '0' '0' '0'\n",
      " '0' '2' '0' '0' '2' '0' '0' '0' '2' '0' '2' '0' '6' '0' '2' '4' '4' '4'\n",
      " '2' '12' '0' '0' '0' '8' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '14' '2'\n",
      " '0' '0' '0' '0' '0' '0' '2' '2' '6' '0' '0' '0' '0' '0' '0' '2' '0' '0'\n",
      " '4' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '4' '0' '0' '0'\n",
      " '4' '0' '0' '0' '6' '0' '4' '2' '0' '2' '2' '0' '0' '0' '0' '4' '0' '0'\n",
      " '0' '0' '4' '0' '0' '10' '0' '0' '0' '0' '10' '0' '2' '0' '0' '4' '0' '0'\n",
      " '0' '0' '0' '0' '0' '2' '10' '0' '0' '0' '0' '0' '0' '0' '0' '12' '4' '0'\n",
      " '10' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '14' '0' '0' '0' '8'\n",
      " '12' '0' '0' '0' '2' '0' '0' '0' '6' '0' '8' '6' '0' '6' '0' '0' '12' '0'\n",
      " '0' '0' '0' '0' '0' '2' '0' '6' '0' '6' '0' '0' '0' '8' '0' '0' '0' '2'\n",
      " '0' '14' '2' '8' '16' '2' '12' '0' '8' '2' '0' '10' '0' '0' '0' '10' '0'\n",
      " '6' '0' '6' '4' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  offers.loc[:, string_col] = offers[string_col].astype(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_1504\\2049269939.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['2' '0' '2' '2' '0' '2' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '2' '0' '0' '0' '0' '0' '2' '0' '2' '0' '0' '2' '2' '2' '0' '0'\n",
      " '0' '0' '2' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '2' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '2' '0' '0' '2' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '2'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '2' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '2' '4' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '2' '0' '0' '0' '0' '4' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '2' '0' '0' '0' '2' '0' '0' '0' '0' '0' '2' '0' '2' '0' '0' '0' '0'\n",
      " '4' '2' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '2' '4' '0' '0' '0' '0'\n",
      " '0' '0' '0' '2' '0' '2' '2' '0' '2' '0' '0' '0' '0' '0' '2' '0' '0' '0'\n",
      " '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '2' '2' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '2' '0' '2' '0' '0' '0' '0'\n",
      " '0' '4' '0' '0' '0' '0' '0' '2' '2' '0' '2' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '4' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '0' '0' '2' '0' '0' '0' '0' '2' '0' '2' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '2' '0' '0' '2' '0' '4' '0' '0' '0' '0' '0' '0' '0' '2' '2' '0' '0'\n",
      " '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '2' '0' '0' '0'\n",
      " '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '2' '0' '2' '4' '0' '2' '0'\n",
      " '0' '0' '0' '0' '2' '2' '2' '0' '0' '0' '0' '0' '0' '0' '0' '4' '0' '0'\n",
      " '2' '0' '2' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0'\n",
      " '0' '2' '0' '2' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '2' '2' '2' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '2' '0' '0' '0' '2' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '2' '0' '0'\n",
      " '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '4'\n",
      " '0' '2' '0' '2' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '2' '0' '2' '0' '0' '0' '2' '0' '0' '0' '0' '0' '2' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '2' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '2' '0'\n",
      " '0' '0' '2' '0' '0' '2' '2' '2' '2' '0' '4' '0' '0' '0' '0' '0' '2' '0'\n",
      " '2' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '2' '4' '0' '2' '0' '2' '0' '2' '2' '0' '2' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '2' '4' '0' '0' '0' '0' '0' '0' '2' '2' '2'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2'\n",
      " '0' '2' '2' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '2' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '2'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '2' '4' '0' '0' '0' '0' '0' '0' '2' '0'\n",
      " '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '0' '2' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  offers.loc[:, string_col] = offers[string_col].astype(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_1504\\2049269939.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '3' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '5' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '3'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '5' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '3'\n",
      " '0' '0' '0' '0' '5' '5' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0'\n",
      " '0' '0' '0' '0' '0' '0' '5' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '3' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '5' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '3' '0' '0' '0' '3' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  offers.loc[:, string_col] = offers[string_col].astype(str)\n"
     ]
    }
   ],
   "source": [
    "STRING_COLUMNS = [\n",
    "    'rurality', 'offer uni preference', 'interview uni preference', 'deakin bonus', 'anu bonus', 'mq bonus',\n",
    "                  \n",
    "    # already strings\n",
    "    'interviewed?', 'casper quartile', 'uq rmp tier', 'interview opinion', 'interview opinion', 'interview prep hours'\n",
    "]\n",
    "\n",
    "FLOAT_TO_INT_COLUMNS = ['offer uni preference', 'interview uni preference']\n",
    "\n",
    "for string_col in STRING_COLUMNS:\n",
    "    # convert into a string and impute\n",
    "    offers.loc[:, string_col] = offers[string_col].astype(str)\n",
    "    offers.loc[:, string_col] = offers.replace('nan', 'None')\n",
    "\n",
    "    # convert to float if necessary\n",
    "    if (string_col in FLOAT_TO_INT_COLUMNS):\n",
    "        offers.loc[:, string_col] = offers[string_col].apply(lambda x: x.split('.')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         4\n",
       "1         1\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "947    None\n",
       "948    None\n",
       "949    None\n",
       "950       1\n",
       "951       1\n",
       "Name: offer uni preference, Length: 952, dtype: object"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers['offer uni preference']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save with the index\n",
    "offers = offers.reset_index()\n",
    "offers.to_csv(f\"{RELATIVE_OUT}/offer.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(offers[\"interview uni\"] == UQ_NAME).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uq_mask(series):\n",
    "    return series.apply(lambda x: UQ_NAME in x if not pd.isna(x) else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                       952\n",
       "rurality                    952\n",
       "s1 score                    952\n",
       "s2 score                    952\n",
       "s3 score                    952\n",
       "uw gamsat                   952\n",
       "w gamsat                    952\n",
       "offer uni                   688\n",
       "offer uni gpa               688\n",
       "offer uni gamsat            688\n",
       "offer uni place type        688\n",
       "offer uni preference        952\n",
       "interviewed?                952\n",
       "interview uni               385\n",
       "interview uni gpa           385\n",
       "interview uni gamsat        385\n",
       "places selected             720\n",
       "interview uni preference    952\n",
       "deakin bonus                952\n",
       "anu bonus                   952\n",
       "mq bonus                    952\n",
       "casper quartile             952\n",
       "uq rmp tier                 952\n",
       "gemsas over other?          688\n",
       "interview opinion           952\n",
       "notes                       567\n",
       "year                        952\n",
       "interview prep hours        952\n",
       "other rejections            142\n",
       "marker                      952\n",
       "dtype: int64"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers.apply(lambda x: x.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1533, 44)\n"
     ]
    }
   ],
   "source": [
    "interview_raw = pd.read_csv(f\"{RELATIVE_IN}/interview.csv\", index_col=0)\n",
    "print(interview_raw.shape)\n",
    "#print(interview_raw.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uw gamsat</th>\n",
       "      <th>w gamsat</th>\n",
       "      <th>interview uni gpa</th>\n",
       "      <th>interview uni gamsat</th>\n",
       "      <th>pref 1 gpa</th>\n",
       "      <th>pref 1 gamsat</th>\n",
       "      <th>pref 2 gpa</th>\n",
       "      <th>pref 2 gamsat</th>\n",
       "      <th>pref 3 gpa</th>\n",
       "      <th>pref 3 gamsat</th>\n",
       "      <th>pref 4 gpa</th>\n",
       "      <th>pref 4 gamsat</th>\n",
       "      <th>pref 5 gpa</th>\n",
       "      <th>pref 5 gamsat</th>\n",
       "      <th>pref 6 gpa</th>\n",
       "      <th>pref 6 gamsat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uw gamsat w gamsat interview uni gpa interview uni gamsat pref 1 gpa  \\\n",
       "0   float64  float64           float64              float64    float64   \n",
       "\n",
       "  pref 1 gamsat pref 2 gpa pref 2 gamsat pref 3 gpa pref 3 gamsat pref 4 gpa  \\\n",
       "0       float64    float64       float64    float64       float64    float64   \n",
       "\n",
       "  pref 4 gamsat pref 5 gpa pref 5 gamsat pref 6 gpa pref 6 gamsat  \n",
       "0       float64    float64       float64    float64        object  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_raw[[col for col in interview_raw.columns if \"gamsat\" in col or \"gpa\" in col]].dtypes.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1533\n",
      "568\n",
      "0\n",
      "568\n"
     ]
    }
   ],
   "source": [
    "print(interview_raw.shape[0])\n",
    "print(interview_raw[\"pref 6 gamsat\"].apply(lambda x: isinstance(x, str)).sum())\n",
    "print(interview_raw[\"pref 6 gamsat\"].apply(lambda x: isinstance(x, int)).sum())\n",
    "print(interview_raw[\"pref 6 gamsat\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>669</th>\n",
       "      <th>879</th>\n",
       "      <th>508</th>\n",
       "      <th>49</th>\n",
       "      <th>878</th>\n",
       "      <th>1461</th>\n",
       "      <th>557</th>\n",
       "      <th>782</th>\n",
       "      <th>924</th>\n",
       "      <th>664</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pref 6 gamsat</th>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>67.75</td>\n",
       "      <td>\\n</td>\n",
       "      <td>65.25</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              669  879  508    49   878    1461 557  782  924  664 \n",
       "pref 6 gamsat   \\n   \\n   \\n  67.75   \\n  65.25   \\n   \\n   \\n   \\n"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_raw[\"pref 6 gamsat\"][interview_raw[\"pref 6 gamsat\"].notna()].sample(10).to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_raw[\"pref 6 gamsat\"] = interview_raw[\"pref 6 gamsat\"].apply(\n",
    "    lambda x: x.strip() if isinstance(x, str) else x\n",
    ")\n",
    "interview_raw[\"pref 6 gamsat\"] = pd.to_numeric(interview_raw[\"pref 6 gamsat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "[        nan 64.         63.66666667 62.66666667 66.5        67.75\n",
      " 63.33333333 66.         68.75       69.         63.5        68.25\n",
      " 71.25       69.5        70.         65.66666667 71.         63.\n",
      " 65.75       63.25       67.         65.         61.         69.75\n",
      " 56.75       61.75       68.         58.25       71.75       66.67\n",
      " 62.         64.67       62.33       65.33       70.33       64.25\n",
      " 62.67       68.5        62.75       65.67       62.25       59.\n",
      " 65.25       61.67       69.25       67.25       52.67       58.        ]\n"
     ]
    }
   ],
   "source": [
    "print(interview_raw[\"pref 6 gamsat\"].count())\n",
    "print(interview_raw[\"pref 6 gamsat\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switching to Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_1504\\3400065161.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '2' '0' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  interview_raw.loc[:, string_col] = interview_raw[string_col].apply(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_1504\\3400065161.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '4' '0' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  interview_raw.loc[:, string_col] = interview_raw[string_col].apply(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_1504\\3400065161.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  interview_raw.loc[:, string_col] = interview_raw[string_col].apply(str)\n",
      "C:\\Users\\mtp63\\AppData\\Local\\Temp\\ipykernel_1504\\3400065161.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['nan' 'nan' 'nan' ... '0.0' '0.0' '0.0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  interview_raw.loc[:, string_col] = interview_raw[string_col].apply(str)\n"
     ]
    }
   ],
   "source": [
    "STRING_COLUMNS = [\n",
    "    # numeric\n",
    "    'deakin bonus', 'anu bonus', 'mq bonus', 'undf bonuses', 'unds bonuses', 'uow bonuses',\n",
    "    \n",
    "    # other stuff\n",
    "    'uq tier', 'casper quartile', 'deakin tier', 'unimelb gam'\n",
    "]\n",
    "\n",
    "for string_col in STRING_COLUMNS:\n",
    "    interview_raw.loc[:, string_col] = interview_raw[string_col].apply(str)\n",
    "    interview_raw.loc[:, string_col] = interview_raw.replace('nan', 'None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undf bonuses\n",
       "None      1508\n",
       "WA Res      24\n",
       "HDR          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_raw[STRING_COLUMNS[3]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing UQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNI_COLUMNS = [\"interview uni\"] + [f\"pref {i+1} uni\" for i in range(6)]\n",
    "UQ_NAME = \"The University of Queensland\"\n",
    "RMP_ENDINGS = [\"(DD MP)\", \"(CQ-WB RMP)\", \"(RMP/DDMP)\"]\n",
    "METRO_ENDING = \"(Greater Brisbane)\"\n",
    "\n",
    "# fixing the queensland column\n",
    "interview = interview_raw.copy()\n",
    "\n",
    "# change the MD and WB to correct types\n",
    "for uni_column in UNI_COLUMNS:\n",
    "    interview.loc[interview[uni_column].isin([f\"{UQ_NAME} {x}\" for x in RMP_ENDINGS ]), uni_column] = f\"{UQ_NAME} (RMP)\"\n",
    "    interview.loc[interview[uni_column] == f\"{UQ_NAME} {METRO_ENDING}\", uni_column] = f\"{UQ_NAME} (Metro)\"\n",
    "\n",
    "# make the notes lowe case\n",
    "interview.loc[:, \"notes\"] = interview[\"notes\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interview uni\n",
       "The University of Melbourne               300\n",
       "The University of Notre Dame Sydney       198\n",
       "Deakin University                         126\n",
       "Griffith University                       110\n",
       "The University of Western Australia       108\n",
       "The University of Notre Dame Fremantle    101\n",
       "The University of Wollongong               93\n",
       "The University of Queensland (RMP)         83\n",
       "The University of Queensland               74\n",
       "Australian National University             62\n",
       "The University of Queensland (Metro)       60\n",
       "Macquarie University                       52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#interview.groupby(\"interview uni\")[\"year\"].value_counts()\n",
    "interview[\"interview uni\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save with the index\n",
    "interview = interview.reset_index()\n",
    "interview.to_csv(f\"{RELATIVE_OUT}/interview.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
